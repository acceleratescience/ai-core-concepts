{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Accelerate Science's Core AI Concepts","text":"<p>Machine learning has become an indispensable tool for researchers across disciplines.</p> <p>In response, Accelerate Science\u2019s programme offers tailored support to help those who would like to learn more about AI. </p> <p>This online course covers the core concepts of AI for researchers who are at the beginning of exploring AI in their work. It's designed as an introduction to the core concepts behind AI, demystifying some of the field's vocabulary, helping researchers to understand how they might use AI in their own work, and signposting ways to get started. </p> <ul> <li> <p> What is AI?</p> <p>A look at what AI is, and isn't</p> </li> </ul> <ul> <li> <p> Supervised Learning</p> <p>Supervised Learning</p> </li> </ul> <ul> <li> <p> Unsupervised Learning</p> <p>Unsupervised Learning</p> </li> </ul> <ul> <li> <p> Reinforcement Learning</p> <p>Reinforcement Learning</p> </li> </ul> <ul> <li> <p> Generative AI</p> <p>Generative AI</p> </li> </ul> <ul> <li> <p> Natural Language Processing</p> <p>Natural Language Processing</p> </li> </ul> <ul> <li> <p> Computer Vision</p> <p>Computer Vision</p> </li> </ul> <ul> <li> <p> Training AI Models</p> <p>Training AI Models</p> </li> </ul> <ul> <li> <p> Evaluating AI Models</p> <p>Evaluating AI Models</p> </li> </ul> <ul> <li> <p> Data for AI</p> <p>Data for AI</p> </li> </ul> <ul> <li> <p> Responsible Research and Innovation</p> <p>Responsible Research and Innovation</p> </li> </ul> <ul> <li> <p> Some Practical Advice</p> <p>Some practical advice</p> </li> </ul> <ul> <li> <p> Next Steps</p> <p>Next Steps</p> </li> </ul>"},{"location":"#contact","title":"Contact","text":"<p>If you can't find what you need, or just need more help</p> <p>CONTACT US </p>"},{"location":"data/","title":"Data for AI","text":""},{"location":"data/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>What data is and how it's stored</li> <li>How much data you need and how dataset size impacts your options</li> <li>Data issues</li> <li>Where researchers look for data</li> </ul>"},{"location":"data/#working-with-data","title":"Working with data","text":"<p>To build an AI model, you'll be working closely with data. Data can make or break your project, and so it's crucial to think carefully about the data you're using and how it'll impact your task. </p> <p>The data you use for your AI work is tightly connected with what you're trying to achieve. If you're building a system that translates between languages, then your data will be text in the languages you're interested in. If you're diagnosing medical conditions, then your data will likely be medical test results or biomarkers. </p> <p>Data can be stored in several formats, whether it's in a spreadsheet, as files on your local machine, or in the cloud.</p> <p>It is transformed into something computer readable by feature extraction, which is the step to convert your data into a numerical format that AI models can ingest.</p>"},{"location":"data/#data-splits","title":"Data Splits","text":"<p>It's important when training to separate your data into training, development, and test sets.</p> <ul> <li>Training data is used for adjusting the model parameters during the model training phase</li> <li>Development data is used to judge the model performance at intermediate stages, and may be used for tuning hyperparameters</li> <li>Test data is used at the end of development to estimate how well your model performs on unseen data</li> </ul> <p>It is important to ensure that there's no leakage or cross-over between training and testing data.</p> <p>One really common way that leakage happens is during data pre-processing. It's common to estimate some transformations of the data. For example, normalising it so that the mean and standard deviation are 0 and 1. Estimating the transformations should be done only on the training set, and then should be applied to the development and test data. </p> <p>If you have a small set, and carving out separate test and development sets leaves you with only a very small amount of training data, then a technique like k-fold cross validation may be appropriate. </p> <p>If you have a dataset, then a common rule of thumb is to use 80% of data for training, 10% for development, and 10% for testing. However, you do need to be sure that 10% of data you have left for testing is enough data that you can see statistically significant results.</p> <p>Usually, you'd create these data splits by randomly sampling your entire set. There may be cases though where you want to do something different. One example is stratified sampling, where you split your data into segments and sample from each segment to be sure you have full representation in your test set. Another example is where you have multiple data points from multiple people, and you want t ensure that a single person's data doesn't span the sets. For example, suppose you are working with audio files and you would like to keep each speaker's data in a single split.</p> <p>If you move to collecting data from multiple different sources, you might need to carefully think about how to split your data. If you use synthetic data in your training set, you might not split that synthetic data between your test sets. </p>"},{"location":"data/#how-much-data-do-you-need","title":"How much data do you need?","text":"<p>This is a commonly asked question, but unfortunately there's no hard and fast answer! Sometimes the only way to know if you have enough data is to build a model and test its performance. Some of the factors that influence data needs are:</p> <p>Task: some tasks are inherently easier than others, and require less data to model. </p> <p>Model: the larger and more complex your model, the more data you need.</p> <p>Diversity: you also need diversity in your data as well as quantity. Simply adding more data that has the same information won't really improve your model.</p> <p>Starting point: starting from scratch usually requires more data than if you're finetuning an already existing model.</p> <p>Data dimension: the higher the dimensionality of your data, the more of it you need to model effectively. </p>"},{"location":"data/#data-issues","title":"Data issues","text":"<p>Data is often the source of many problems researchers encounter when building AI models.</p> <p>A typical issue arises when there is a difference between the training and testing data that you're using. Perhaps training data was collected in one way, and test data in another. </p> <p>A similar issue arises when data distributions change over time, and is called data drift. This happens all the time in real-world scenarios! Consider the language that we use. Models trained on language from 200 years ago probably wouldn't do well on today's language! And even models trained 20 years ago might miss some crucial language changes. </p> <p>Problems with data can sometimes be very subtle. Consider this paper that deliberately trained a poor classifier to distinguish wolves and huskies. In this setup, the images of wolves all had snow in the background, while images of huskies didn't have snow. Rather than distinguish the wolves and huskies based on their appearance, the classifier actually learned to distinguish snowy from non-snowy scenes. </p> <p>Skewed data is where there is an imbalance in the amount of data between classes, because one class is far more common than another. This is common in, say, medical contexts where the number of people with a particular condition is far lower than those without. </p> <p>Finally, depending on what you're doing, your data may contain personal and sensitive information about people. Keeping it safe and secure is crucial.</p> <p>Often, if you have trouble getting a machine learning model to perform well, the first place to start looking for issues is in the data that you're using to train your model. </p>"},{"location":"data/#where-to-get-data-from","title":"Where to get data from","text":"<ul> <li>Collection: can you collect the data you need from volunteers, or some other way?</li> <li>Open source: there are many open source datasets available, which might work for your task. Many open source sets are ready split into test &amp; training sets for you to use.</li> <li>Experimental results: it's common to use AI methods on experimental data from your work or your lab's results. </li> <li>Synthetic: Generating synthetic data is an increasingly common way to create training data. </li> <li>Partnerships: partnering with other labs or organisations to share data can be an effective way to boost the amount of data you're working with.</li> </ul>"},{"location":"data/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"evaluating/","title":"Evaluating AI Models","text":""},{"location":"evaluating/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>Using test data to robustly evaluate models</li> <li>Quantative vs qualitative evaluation</li> <li>Evaluation metrics</li> <li>Error analysis tools including stratification, confusion matrices &amp; ROC</li> </ul>"},{"location":"evaluating/#overview","title":"Overview","text":"<p>All machine learning models make mistakes. Consider a binary classification supervised model that's used to identify spam emails, and has been trained on a training dataset (circles). As the model weights have been trained using the training data, we can't use that data to see how well the classifier performs. That's a bit like seeing the exam questions ahead of time! To judge how well the classifier performs, we test its performance on a separate test set (triangles). </p> <p></p>"},{"location":"evaluating/#data","title":"Data","text":"<p>It's important when training to separate your data into training, development, and test sets.</p> <ul> <li>Training data is used for adjusting the model parameters during the model training phase</li> <li>Development data is used to judge the model performance at intermediate stages, and may be used for tuning hyperparameters</li> <li>Test data is used at the end of development to estimate how well your model performs on unseen data</li> </ul> <p>It is important to ensure that there's no leakage or cross-over between training and testing data.</p>"},{"location":"evaluating/#qualitative-vs-quantative-evaluation","title":"Qualitative vs Quantative Evaluation","text":"<p>There are two main categories of way to evaluate how well your model is working</p> <ol> <li>Quantative evaluations devise an automated metric which you can automatically compute on your test set to give a score</li> <li>Qualitative evaluations ask people to interact with your model and judge it</li> </ol> <p>For some tasks, like spam email detection, we can automatically compute an accuracy metric. For other tasks, like machine translation, there are many possible correct answers and it's hard to find a good automated metric. Hence, the way to judge performance is by having people evaluate the translations.</p> <p>Qualitative evaluations are expensive to perform, and so in practice it's often helpful to have a mix of quantitative and qualitative metrics. </p>"},{"location":"evaluating/#metrics","title":"Metrics","text":"<p>There are a wide range of metrics in use for different tasks, so the best thing to do is to look at the literature and see what people are using. However, some common metrics exist. For classification:</p> <ul> <li>Accuracy is simply how often the classifier is right. This is computed by comparing the classifier's prediction against the ground truth human labels in a test set. </li> <li>Precision is a measure of how many of your positive classifications were correct. For the spam email case, it's the proportion of emails the model identified as spam that actually were spam. </li> <li>Recall tells you what proportion of your positives were correct. For the spam email case, it's the proportion of actual spam emails the model identified as spam.</li> </ul> <p>Precision and recall are used together. An increase in one usually means a decrease in the other. </p> <p>For regression tasks,</p> <ul> <li>RMSE root mean squared error, is a measure of how far on average your predictions are from the ground truth label. </li> </ul> <p>You'll need to use your judgement to interpret a particular metric. An accuracy or 5% may be great for one task, but terrible for another. </p>"},{"location":"evaluating/#error-analysis","title":"Error Analysis","text":"<p>Usually, you 'll want to look deeper at the kind of errors that a model is making, in order to identify places where you can improve. Some useful ways to view errors are:</p> <ul> <li>Confusion matrix: a plot showing which categories were confused with each other.</li> <li>ROC a graph that shows classification error as you change the classifier's threshold.</li> <li>Stratification of your test data into different subgroups, to compute the error on those. This can help identfy sub-populations with different performance. </li> </ul>"},{"location":"evaluating/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"generative-ai/","title":"Generative AI","text":""},{"location":"generative-ai/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>What generative AI is, and where you can use it</li> <li>What frontier or foundation models are and the pros &amp; cons of using them</li> <li>Some real-world examples of generative AI in research</li> </ul>"},{"location":"generative-ai/#overview","title":"Overview","text":"<p>Since 2017, there has been a lot of work in the area of generative AI. Broadly speaking, generative AI refers to models that generate content, usually in the form of images, text, video or audio.</p> <p></p> <p>In many ways, generative AI is similar to supervised learning. The predictions that the models make are actually predictions about the content itself. You might hear the term self-supervised to describe these models. This is because we don't need a person to label the data as the supervision signal is present within the data itself. </p> <p>One big difference between generative AI and more classic supervised learning is that the kind of content (image, text, audio etc.) that's popular for generative AI models is widely available online. This means that organisations can build larger and larger models with massive training data sets. </p> <p>Generative AI was spurred on recently by the introduction of the transformer model (a kind of neural network) in 2017, and more recent work in building large models. In the field of natural language processing (NLP), transformer models have had a huge impact. Generative AI in NLP uses the task of language modelling - the task of predicting the next word in a sentence. This is a supervised learning task. Given a sequence of words, the model's goal is to predict the next word. It doesn\u2019t require large amounts of effort to label the text data for training because \u201cnext word\u201d is inherently there in the data. A language model is essentially a very powerful autocomplete model, but additional types of training is used to turn a basic language model into a chat model like ChatGPT. </p> <p>What\u2019s interesting about Generative AI models for NLP is that when trained on large amounts of data, they are able to do several tasks that they weren\u2019t explicitly trained to do. For example, with a large amount of multilingual training data, they are able to translate between languages. This is described as zero shot learning.</p> <p>Tasks involving image and audio processing tend to make use of diffusion models rather than transformers. </p>"},{"location":"generative-ai/#frontierfoundation-models","title":"Frontier/Foundation Models","text":"<p>Generative AI models are expensive to train, due to their large size and the large amount of training data. There's a current trend of building larger and larger models. That means that only a handful of organisations can afford to build their own models from scratch. A typical way of working now is that these large \u2018foundation models\u2019 trained once by an organisation with the money and resources to do so, are then released publicly. Others can then use the models directly, or fine-tune them for their own projects with a small amount of data - far smaller than the amount of data that\u2019s needed to build their own large model from scratch.</p> <p>There are some considerations to take into account when using foundation models:</p> <ul> <li>For many public models, there are varying levels of openness. Often the model weights might be available, but we might not know about the training data that was used. </li> <li>If a model is hosted by an organisation behind an API, we cannot be sure what changes they are making, and that can affect reproducibility</li> <li>These models are typically trained on large amounts of data from the internet, which brings with it societal biases that become embedded in the model.</li> <li>There's a large environmental cost to using these models.</li> </ul>"},{"location":"generative-ai/#inspiration","title":"Inspiration","text":"<p>Here are two papers that look at applications of some of these models:</p> <ul> <li>An Interdisciplinary Outlook on Large Language Models for Scientific Research</li> <li>An Overview of Diffusion Models: Applications, Guided Generation, Statistical Rates and Optimization</li> </ul>"},{"location":"generative-ai/#more-resources","title":"More Resources","text":"<p>Accelerate Science has two workshops related to generative AI, each with online material that you can work through at your own pace:</p> <ul> <li>LLMs</li> <li>Diffusion Models</li> </ul>"},{"location":"generative-ai/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"image/","title":"Image Processing / Computer Vision","text":""},{"location":"image/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>What Computer Vision (CV) is</li> <li>Some of the tasks that fall under CV</li> </ul>"},{"location":"image/#what-is-computer-vision","title":"What is Computer Vision?","text":"<p>Computer Vision (CV) is the field of AI that's concerned with processing images and video. One of the most popular introductory ML datasets you might come across is MNIST, a set of images of handwritten digits.</p> <p>When we think of images, we usually imagine a photo taken with a camera. However, across the sciences, there are many other sources of image data in use such as X-rays, ultrasound, CT scans, satellite images, electron microscopy etc. The same techniques that are applied to photos are often used in these other image formats. </p> <p>A key model for image processing is the convolutional neural network (CNN). These have been used for many years in computer vision. Recently, with the trend for increases in the dataset and model size, CNNs have proven to be very successful in modelling images. More recently, generative AI has made an impact in the field of computer vision. Models like Dall-E and Stable Diffusion are able to generate a wide range of images from a text prompt. These techniques make use of diffusion models, a technique that was introduced in 2015.</p>"},{"location":"image/#cv-tasks","title":"CV Tasks","text":"<p>Computer vision is widespread, and many CV tasks exist including:</p> <ul> <li>Classification: classifying an image into one of several categories, e.g. classifying the handwritten digit in the MNIST task.</li> <li>Segmentation: segmenting an image into different parts. For example, identifying boundaries of objects within an image. In a medical image this could also be something like identifying the boundaries of a tumour. </li> <li>Image generating: creating images from text descriptions, as is done by Stable Diffusion and Dall-E. </li> <li>Denoising and enhancement: removing noise from images and enhancing them</li> <li>Pose detection: identifying the pose of the person (or animal) in an image</li> </ul>"},{"location":"image/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"next-steps/","title":"Next Steps","text":""},{"location":"next-steps/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>How to get started learning more about AI</li> <li>What help and support is available</li> </ul>"},{"location":"next-steps/#resources","title":"Resources","text":"<p>Now you have an idea how and where AI is used, and hopefully can identify some places in your research where you see the potential for concrete applications of AI.</p> <p>Accelerate Science provides resources to support you in your next steps:</p> <ul> <li>Our Resource hub contains links to more in depth lessons and tutorials</li> <li>We run several workshops, including on Generative AI topics of LLMs and Diffusion models</li> <li>We provide AI &amp; Software Engineering help to researchers via our AI Clinic, where you can file a ticket to receive 1-1 help</li> <li>We run regular drop-in AI Cafe sessions where you can turn up and talk with an expert</li> </ul>"},{"location":"next-steps/#what-more-is-there-to-learn","title":"What more is there to learn?","text":"<p>If you do decide to go further and really understand the theory of AI, you\u2019ll need to dig into these topics:</p> <ul> <li>Maths - the theory of machine learning relies on some core maths knowledge, including linear algebra, optimisation, probability and calculus. To understand the theory of AI and ML, and if you want to work on designing your own models and algorithms, you\u2019ll need to learn this maths.</li> <li>Programming - there are some AI tools you can use without any particular expertise (e.g. ChatGPT), but if you want to do anything more complicated with AI then you\u2019ll likely need to know some programming. Python is the language of choice for many ML Scientists, though R is also used in some domains.</li> <li>Data Literacy - AI and ML is all about working with datasets - collecting, cleaning, processing, visualising, aggregating &amp; exploring data. Intuition about data is often built up over time, working with different algorithms, tasks, and datasets.</li> </ul>"},{"location":"next-steps/#where-else-can-i-look","title":"Where else can I look?","text":"<p>There are many free resources online to learn about AI. We also recommend this textbook:</p> <p>Hands-on machine\u00a0learning\u00a0with Scikit-Learn,\u00a0Keras,\u00a0and TensorFlow\u00a0: concepts, tools, and techniques to build intelligent systems / Aur\u00e9lien G\u00e9ron.</p> <p>This book has code and exercises that illustrate many of the concepts presented in this course.</p>"},{"location":"next-steps/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"nlp/","title":"Natural Language Processing","text":""},{"location":"nlp/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>What falls under the umbrella of Natural Language Processing (NLP)</li> <li>Some common NLP tasks</li> </ul>"},{"location":"nlp/#what-is-nlp","title":"What is NLP?","text":"<p>Natural Language Processing (NLP) is the umbrella term for techniques that involve processing text data. NLP is a large domain, and there are lots of opportunities to use NLP across a wide range of subjects. Hence, it can be useful for researchers to know some of the ways NLP is used.</p> <p>The field of NLP has been transformed by machine learning in the past couple of decades. Supervised learning techniques were applied across a range of text processing tasks. Recently, the NLP field has moved in the direction of using foundation models and generative AI.</p>"},{"location":"nlp/#nlp-tasks","title":"NLP Tasks","text":"<p>If you want to work with text data in your field, the chances are good that you'll want to use some kind of NLP technology. </p> <p>Many common NLP tasks exist, which have a long line of research into them, including:</p> <ul> <li>Language Modelling is the task of predicting the next word, like an autocomplete. It's the basis of recent progress in NLP relating to generative AI. </li> <li>Machine Translation automatically translates text from a source lanugage to a target language. </li> <li>Summarisation is when a model is used to summarise a long piece of text into a shorter one.</li> <li>Question Answering answering questions where the answer can be found in a text that has been provided. E.g. answering questions from a textbook.</li> <li>Sentiment Analysis analysing whether a piece of text is positive or negative in its sentiment.</li> <li>Named Entity Recognition picking out certain key entities from a phrase. For example, picking out names of cities, countries or people from text. </li> </ul> <p>Many of these tasks have well established benchmark datasets, which researchers use to evaluate the performance of these models in a generic setting. </p>"},{"location":"nlp/#nlp-data","title":"NLP Data","text":"<p>NLP models are typically trained using text data from the internet. This data is often selected to have a broad coverage of general topics. </p> <p>Researchers wanting to use NLP techniques in specific domain or field may need text from that domain for their models, to capture the kinds of vocabulary and phrases that are used. </p>"},{"location":"nlp/#inspiration","title":"Inspiration","text":""},{"location":"nlp/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"practical/","title":"Some Practical Advice","text":""},{"location":"practical/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>Popular tools for getting started</li> <li>Managing experimentation</li> <li>Ways to share your work</li> </ul>"},{"location":"practical/#programming","title":"Programming","text":"<p>If you choose to continue and use AI in your research, you will likely need to learn some programming. Even if you don't intend to train your own models, but simply use what's already been built, you may find that programming is helpful to speed up your work.</p> <p>Most AI and ML work is done in Python. In some fields, R is used as an alternative. Python has great support for machine learning. There are many libraries available to use, such as Pytorch and HuggingFace.</p> <p>Many researchers begin exploring ML code using Notebooks such as Jupyter or Google Colab. These can be a great way to get started exploring, but you might find that once you've made some good progress your code becomes unwieldy and you look for other ways to structure your work. </p> <p>Managing the code for your project is best done using a version control tool like GitHub. A tool like this will allow you to track the changes you make to your code, go back and forth between versions, and easily collaborate with colleagues. </p>"},{"location":"practical/#good-experimental-practice","title":"Good Experimental Practice","text":"<p>Once you've got started with programming, the next challenge is usually managing your experiments and tracking work. It can be easy to rapidly create lots of files and find your files hard to navigate. </p> <p>For recording your work, Model Cards and Data Sheets provide a structured way to log what you've built so that others can understand. </p>"},{"location":"practical/#sharing-your-work","title":"Sharing your work","text":"<p>At the end of your project, sharing your model, data and code with the open source community can be done. Openness is key to scientific rigour. </p> <p>Accelerate Science have a course on packaging software, which you can sign up to, or follow the materials online at your own pace. </p>"},{"location":"practical/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"reinforcement-learning/","title":"Reinforcement Learning","text":""},{"location":"reinforcement-learning/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>What reinforcement learning is, and where you can use it</li> <li>Some real-world examples of reinforcement learning in research</li> </ul>"},{"location":"reinforcement-learning/#overview","title":"Overview","text":"<p>Reinforcement learning is an area of AI and ML looking at tasks where the computer has to take a series of moves in an uncertain and changing environment, to achieve a particular goal.</p> <p>Reinforcement Learning models learn through trial and error, and are given a reward signal if they achieve their goal. The models aim to optimise their reward. In practice, it's used much less than supervised and unsupervised learning. </p>"},{"location":"reinforcement-learning/#reinforcement-learning-use-cases","title":"Reinforcement Learning Use Cases","text":"<p>RL is used in scenarios like:</p> <ul> <li>Playing games, where the computer can choose to make optimal moves but there is some uncertainty about the moves its opponent may make. </li> <li>Human-computer dialogue, where again the computer can choose an optimal utterance, but there is uncertainty about what the person will say and how that affects the trajectory of the conversation. </li> <li>Controlling robots in real-world environments where there is uncertainty about how the environment changes over time.</li> </ul> <p>In each of these tasks, it\u2019s hard to judge in isolation whether a single turn or move by the computer is optimal. Yet, we do know in the long-term whether the computer achieves its goal.</p>"},{"location":"reinforcement-learning/#inspiration","title":"Inspiration","text":"<ul> <li>One famous example of reinforcement learning is Deepmind's AlphaGo model, that learned to play the game Go</li> </ul>"},{"location":"reinforcement-learning/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"responsible-research-innovation/","title":"Responsible Research and Innovation","text":""},{"location":"responsible-research-innovation/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>Some of the limitations of AI models</li> <li>The wider risks of AI</li> <li>Regulation that might apply</li> </ul>"},{"location":"responsible-research-innovation/#ai-model-limitations","title":"AI model limitations","text":"<p>When considering AI in your research, it's important to know about some of the limitations of current AI models. These include:</p> <p>Models don't have 100% accuracy, and so aren't appropriate for all scenarios or tasks. This needs to be taken into account in the design of the scenario you imagine AI to be used in. In safety critical tasks, they may always need human oversight. </p> <p>Appropriateness some tasks just aren't appropriate for AI because they are too noisy or unpredictable. Often, if it sounds too good to be true, then it is! </p> <p>The black-box nature of many models mean that it can be difficult to understand or interpret why AI models make the predictions that they do. For some domains, this can be challenging. </p> <p>Hallucinations are the name given to a specific kind of error made by language models outputting factually incorrect information. </p>"},{"location":"responsible-research-innovation/#risks-and-concerns","title":"Risks and Concerns","text":"<p>There are also a number of wider risks and concerns about the field of AI.</p> <p>ML models learn from the data they are trained on, which means that they learn and reflect any bias that was present in the training data. This can be particularly harmful if the models were trained on data scraped from the internet, which contains societal biases - like racial and gender - that we do not want to propagate. </p> <p>The environmental cost of building and using ML models is in the spotlight. These models require large amounts of computing power to build and use, and hence use significant amounts of energy. Reducing the carbon footprint of AI is top of many people's mind. </p> <p>Due to the mistakes that ML models make, it's important to think about accountability and human oversight. Leaving ML models to make critical decisions with no oversight raises the question about who remains accountable and responsible when the system makes the wrong decision, especially in tasks where a wrong decision can cause harm. </p> <p>From a scientific research perspective, ensuring reproducibility is important. However, in the fast-paced field, reproducibility can be neglected. It is hard to explain the decisions of ML models, and in many cases explainability and transparency are important. </p> <p>ML models are trained on data, and it's very important to know the source of data. Much data is copyrighted, and we may need consent from the owners of that data in order to use it.</p> <p>As with all technology, there is a potential for misuse. For researchers, the idea that their work can be misinterpreted and misused might seem like a far-off concern. However, it's important to consider at the outset how our work might be used in ways we don't support. </p>"},{"location":"responsible-research-innovation/#regulation","title":"Regulation","text":"<p>Regulation for AI is being developed, and this is a shifting area. Always do your own research into regulations that might apply to your research. </p> <p>The first AI law to pass is the EU's AI act. This regulation has some banned uses of AI. It also carves out some high-risk applications that come with obligations if they are deployed. Most of the act doesn't apply to research, but could come into force if you move to commercialise your work.</p> <p>Other jurisdictions are crafting laws and guidelines that may come into force. </p>"},{"location":"responsible-research-innovation/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"supervised-learning/","title":"Supervised Learning","text":""},{"location":"supervised-learning/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>What supervised learning is, and where you can use it</li> <li>The difference between classification and regression</li> <li>Some of the supervised learning algorithms you might encounter</li> <li>Some real-world examples of supervised learning in research</li> </ul>"},{"location":"supervised-learning/#what-is-supervised-learning","title":"What is supervised learning?","text":"<p>Supervised learning is one of the most widely used types of machine learning in the field of AI. Supervised models make predictions about their inputs. They learn how to make those predictions from a dataset of examples that are labelled with the correct prediction (also called the ground truth).</p> <p>Our job in using supervised learning is to define what the input and output of a model should be, to obtain the labelled data, and then to train the model to make accurate predictions. </p> <p></p> <p>One example of supervised learning is that of predicting whether an email is spam or not. In this example, there are two categories, or classes - SPAM and NOT_SPAM.</p> <p>Our machine learning models cannot directly accept email text as input, so first we extract numerical features from each of the emails. Three features might be, for example, the length of the email, the number of spelling mistakes, and the number of dollar signs in the email. </p> <p></p> <p>By training the model directly on a dataset of emails that have been labelled as being spam or not, the model can learn the patterns that identify the two types of email, and then predict for a new email whether it is spam or not. </p>"},{"location":"supervised-learning/#classification-and-regression","title":"Classification and Regression","text":"<p>Supervised learning can either be classification or regression.</p> <p>Classification is where the output is one of a fixed number of categories. This could be a binary classification task where there are exactly two possible outputs, like the example above of spam email detection.  You can think of the model as finding a line to separate the two classes, as here:</p> <p></p> <p>Usually, there's some overlap between our classes, but we can find a good way to separate them. Usually though, classifiers find a way to separate two classes that is more complex than just a straight line. </p> <p>A different task might have multiple categories that an input could belong to. For example, recognising the face of a person in a photo. There are many possible people who could be pictured in the photo, and each person is a possible category.</p> <p></p> <p>In other scenarios, an input might have more than one label. For example, a photo might have two or more different people in it, and we'd like to identify each. This is called multi-label classification, because each photo has more than one label associated with it.</p> <p>Sometimes the number of classes can be very large, in the thousands or millions, as in the case of many language processing tasks. Automatically translating text from one language to another is a supervised task, where the model predictions are words in the target language. </p> <p>Regression is similar to classification, except that the output is a continuous number rather than a discrete class. Examples might be predicting the toxicity of a molecule on a scale. Fitting a line of best fit is a simple kind of regression. </p> <p></p>"},{"location":"supervised-learning/#feature-extraction","title":"Feature Extraction","text":"<p>It's worth noting that machine learning models require numerical inputs, and you'll need to consider in designing your setup. Some tasks naturally have numerical inputs already - whether that's data from sensors, medical tests, pixel values or some other kind of data that's naturally a number. In other tasks, like in text processing, we need to convert our input to a numerical format by extracting features.</p>"},{"location":"supervised-learning/#examples-of-supervised-learning","title":"Examples of Supervised Learning","text":"<p>Examples of supervised learning tasks include:</p> Task Input Prediction Segment tumours in medical images Medical images Areas which are tumours Toxicity prediction Chemical formula Toxicity Medical Diagnosis Biomarkers, test results etc. Diagnosis Automated transcription Audio files Written transcription Machine translation Text in the source language Text in the target language"},{"location":"supervised-learning/#types-of-supervised-learning-model","title":"Types of Supervised Learning Model","text":"<p>Some of the common supervised learning algorithms you might encounter are:</p> <ul> <li>Linear Regression</li> <li>Logistic Regression</li> <li>Decision Trees </li> <li>Support Vector Machines</li> <li>Neural Networks</li> </ul> <p>Much of the recent excitement around AI focuses on neural network approaches. However, depending on your data and task, the other algorithms may be more practical to use.</p>"},{"location":"supervised-learning/#top-tips-for-getting-started","title":"Top Tips for getting started","text":"<ol> <li>A great place to begin is by thinking about the task you want to used supervised learning for. Can you define your task as a supervised learning one? What are the inputs and predictions of your model?</li> <li>Next, think about the data you have. Can you label it easily?</li> <li>Evaluating your model is also important, and at this point it's feasible to think about how you'll evaluate whether your system is working. What metrics could you use?</li> <li>What are the risks and concerns with your proposed work?</li> </ol> <p>Once you've answered these questions, you're ready to move onto training a model.</p>"},{"location":"supervised-learning/#inspiration","title":"Inspiration","text":"<p>Find more examples of research using supervised learning on Accelerate's blog:</p> <ul> <li>Nicola Moloney talks about using supervised learning to predict where proteins are localised within a cell</li> <li>Joyce Nakatumba-Nabende discusses how speech recognition can be deployed to help farmers in Uganda</li> <li>Yizhou Wan tells us how AI can be used to segment brain tumours in images, and to estimate their volume</li> <li>Chris Bannon hopes to predict whether someone's gut biome or metabolic marker levels are that of a healthy person, or whether they have a metabolic or bowel condition</li> </ul>"},{"location":"supervised-learning/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"training/","title":"Training ML Models","text":""},{"location":"training/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>What it means to train an AI model</li> <li>How to use data for robust training, development and testing</li> <li>Over and under fitting</li> <li>Tuning hyperparameters</li> <li>Transfer learning and fine tuning</li> </ul>"},{"location":"training/#building-machine-learning-models","title":"Building Machine Learning Models","text":"<p>Building a machine learning model involves:</p> <ol> <li>Deciding on the task and collecting data; labelling that data</li> <li>Training a model on a 'training set' of your data</li> <li>Evaluating the model on a separate 'development set', to see how well it does</li> <li>Investigating the errors to see where you can improve</li> </ol> <p>This tends to be an iterative process, not a linear one, so you may need to loop through these steps several times to get a model that works. Once you have a model that works well, you can evaluate its final performance on a 'test set'.</p> <p></p>"},{"location":"training/#supervised-model-training","title":"Supervised Model Training","text":"<p>In a supervised learning scenario, model training is the process of feeding data examples to your model so that it can learn the patterns that are present. Models themselves consist of parameters, and training is the process of learning the values of those parameters. The number of parameters varies wildly between models. A small linear regression model might have in the order of 10 parameters, while a state-of-the-art generative AI model might have 10 billion parameters. </p> <p>A linear regression model trained on one dataset might have the same number of parameters as that trained on another, but the parameter values, or weights, are different because they've been learned from the data.</p> <p>The training algorithm itself is also an iterative process. You feed training data into the model, then the algorithm figures out how wrong the model is for these data points and makes small adjustments to the parameters to perform a little better. Over time, with lots of iterations passing over the training dataset, the parameters converge to a place where they model the training data well. You often don't need to know the details of the training, as there are powerful software libraries that handle the implementation. </p>"},{"location":"training/#data","title":"Data","text":"<p>It's important when training to separate your data into training, development, and test sets.</p> <ul> <li>Training data is used for adjusting the model parameters during the model training phase</li> <li>Development data is used to judge the model performance at intermediate stages, and may be used for tuning hyperparameters</li> <li>Test data is used at the end of development to estimate how well your model performs on unseen data</li> </ul>"},{"location":"training/#over-and-under-fitting","title":"Over and under fitting","text":"<p>Two ways that training can be derailed are over- and under-fitting.</p> <p>Overfitting is where you have a small amount of data and a complex model, so the model learns to model the training set really well. In this case, the model will perform really well on the training set, but poorly on your test set. </p> <p>Underfitting is the opposite, where you might have a lot of data and a simple model, so the model isn't able to approximate the data well. In this case the model will perform poorly on both your training and test set. </p>"},{"location":"training/#hyperparameters","title":"Hyperparameters","text":"<p>The purpose of model training is to find optimal values for the model parameters. However, there are other parameters in machine learning that aren't part of the model. These are called hyperparameters.</p> <p>These might be, for example, the number of layers in your neural network, or the learning rate of your training algorithm. The purpose of a development set is to have data for tuning the hyperparameters. This lets us keep the test set held out, and avoid overfitting.</p>"},{"location":"training/#transfer-learning-and-fine-tuning","title":"Transfer Learning and Fine Tuning","text":"<p>You do not always need to train a model from scratch. Often, there can be a model out there which you can use as a starting point. Then, you would finetune that model to your data, or use transfer learning.</p> <p>Finetuning is where you keep the model architecture as it is, and just train the model a bit more on your data.</p> <p>Transfer learning is similar to finetuning, but with the understanding that you're training the model for a different task than the one it was originally trained to do. With neural networks, this typically means replacing the last layer with one which is designed for your task. </p>"},{"location":"training/#top-tips-for-getting-started","title":"Top Tips for getting started","text":"<ol> <li>Look at what ML models exist. Hugging Face, for example, has a large repository of models available to use. Or in your field, perhaps a relevant group has released a model onto GitHub.</li> <li>Consider whether you can build a baseline system without ML/AI. This will be a simple first step, and likely give you some insight into your problem. </li> <li>Prototype - start with a small model and a simple baseline; Start with a small dataset to get your setup working, before increasing the amount of data</li> <li>Ensure there's no leakage between your test and training data</li> <li>Make use of open source libraries, models and data</li> </ol>"},{"location":"training/#inspiration","title":"Inspiration","text":""},{"location":"training/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"unsupervised-learning/","title":"Unsupervised Learning","text":""},{"location":"unsupervised-learning/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>What unsupervised learning is, and where you can use it</li> <li>Unsupervised learning tasks including clustering, outlier detection and dimensionality reduction</li> <li>Some real-world examples of unsupervised learning in research</li> </ul>"},{"location":"unsupervised-learning/#overview","title":"Overview","text":"<p>Supervised learning is the most popular form of AI. However, supervised learning requires labelled data, which can be difficult or expensive to obtain. Most of the data in the world is unlabelled. Unsupervised learning helps us make sense of unstructured and unlabelled data.</p> <p>Three common unsupervised algorithms are clustering, dimensionality reduction and anomaly detection.</p>"},{"location":"unsupervised-learning/#unsupervised-learning-algorithms","title":"Unsupervised Learning Algorithms","text":"<p>Clustering</p> <p>Clustering is the process of taking your data and discovering sub-groups, or clusters, that are sufficiently similar to each other. Unlike classification in supervised learning, where we know the groups ahead of time, clustering uncovers the structure of the groups in a larger population.</p> <p>Suppose you're working with medical data. You know that some groups of people respond differently to treatment than others, but you don't know the factors that drive this. A clustering algorithm might group your participants into different clusters that potentially allow you to better explain what's going on.</p> <p></p> <p>Other places that people have used clustering include uncovering structure in archeological data, clustering sounds and speakers together, identifying sub-groups of study participants etc. </p> <p>K-means and DBSCAN are popular clustering algorithms. You may need to give the number of clusters before running the clustering algorithm, or you might use an automated method to try and find which number of clusters best fits the data. </p> <p>Dimensionality reduction</p> <p>High dimensional data is hard to work with. The first thing we usually notice is that it's hard to visualise well in high dimensions, so that you can explore what the data looks like. A high number of dimensions also imacts the number of parameters your AI model needs to model the data. The more parameters a model has, the larger model and more data you need. This is the curse of dimensionality.</p> <p>Reducing the dimensionality of your data can be one way to work with it effectively. Projecting down to 2- or 3-dimensions means that you can plot it on a graph to view.</p> <p></p> <p>Principal Component Analysis (PCA), t-SNE, and UMAP are popular dimensionality reduction algorithms that you might see used. </p> <p>Anomaly Detection</p> <p>Anomoly detection is identifying anomolous or rare examples in a dataset, that are inconsistent with the rest of the dataset.</p> <p></p> <p>Examples of this might be in identifying fraudulent and unusual bank transactions, or identifying unusual behaviour that might be a cybersecurity threat. </p>"},{"location":"unsupervised-learning/#inspiration","title":"Inspiration","text":"<p>Find more examples of research using unsupervised learning on Accelerate's blog:</p> <ul> <li>Ema Bauzyte discusses using unsupervised learning to cluster sites in archeology, get more insight about which might be related</li> <li>Jesse Allardice uses dimensionality reduction in Physics, to reduce the complexity of high dimensional data for solar panels</li> <li>Dr Romit Samanta groups patients to better identify subgroups of patients and understand how their biology relates to disease progression</li> </ul>"},{"location":"unsupervised-learning/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"what-is-ai/","title":"What is AI?","text":""},{"location":"what-is-ai/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>What AI is and where it is used</li> <li>Some different definitions of AI and related terms</li> </ul>"},{"location":"what-is-ai/#overview","title":"Overview","text":"<p>AI has grown in popularity over the past decade, and is cropping up in many places. If you're a researcher who wants to use AI in your work, it's helpful to understand what AI is and to think about how you can use it effectively. </p> <p>This short online course is a set of resources to explain the core concepts behind AI, without the need for maths and programming. The goal is to allow researchers to explore the ideas behind AI and consider how they might work in research, before diving in to learn more. </p> <p>Artificial Intelligence (AI) doesn\u2019t have a strict definition. Usually it\u2019s thought of as something like imitating human intelligence. AI systems are used to automate decision making in tasks that typically need some level of intelligence to perform. </p> <p>Machine Learning (ML) is a set of algorithms that learn their behaviour from data. This is in contrast to more traditional computer programming that spells out the rules that a computer must follow. When people talk about AI today, they're mostly talking about machine learning. All of the recent progress in the field of AI has been in machine learning.</p> <p>There are 4 broad categories of ML that this course will explore:</p> <ul> <li>Supervised Learning</li> <li>Unsupervised Learning</li> <li>Reinforcement Learning</li> <li>Generative AI</li> </ul>"},{"location":"what-is-ai/#ai-in-the-real-world","title":"AI in the real-world","text":"<p>In the AI world, we often talk about tasks. A task is something specific that a model might do such as:</p> <ul> <li>Make a decision about whether an email is spam or not</li> <li>Identify people in images</li> <li>Translate text from one language into another</li> <li>Predict whether a transaction on your credit card is fraudulent</li> <li>Automatically transcribe your speech</li> <li>Play the game of Go with an opponent</li> <li>Predict whether an X-ray shows a cancerous mass</li> <li>Predict the toxicity of a chemical compound</li> </ul> <p>Tasks usually have datasets associated with them, which is essentially lots of examples of that task. For example, a spam email detection dataset would consist of many emails. A speech recognition dataset would consist of audio files of people speaking. </p> <p>A dataset might have labels (or annotations), which are the gold standard, or the correct answer, for each item in the dataset. The emails in your spam email dataset would have labels marking each email as spam or not. The audio files in your speech recognition dataset would have accurate transcriptions of the words spoken. </p> <p>Many popular AI tasks have open source datasets that are available to use. Though, depending on the existing research in your field, you might need to go and collect your own dataset. </p> <p>An ML model is built to perform a task, using one or more datasets. The model is usually the artefact that's the result of your experimentation, and it can be used again and again on new data.</p> <p>Under the umbrella of ML, there are many different algorithms. Deep Learning, or Deep Neural Networks, are popular today because they\u2019ve had big success. There are many other algorithms though, some of which may be more suitable for your data.</p> <p>In the next sections, we'll dive into these concepts in more depth. </p>"},{"location":"what-is-ai/#what-will-this-course-give-me","title":"What will this course give me?","text":"<p>This course will dive into some of these concepts and build up an intuition about how AI and ML systems work, without relying on you having any specific maths and programming background knowledge. This will help you understand how and where AI and ML might be useful in your research, desmystify some of the field's vocabulary, and give you the basis to dig further. This course is not a full introduction to the theory and practice of AI, but we'll point you to places to learn more. </p>"},{"location":"what-is-ai/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"}]}