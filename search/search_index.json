{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Accelerate Science's Core AI Concepts","text":"<p>Machine learning has become an indispensable tool for researchers across disciplines.</p> <p>In response, Accelerate Science\u2019s programme offers tailored support to help those who would like to learn more about AI. </p> <p>This online course covers the core concepts of AI for researchers who are at the beginning of exploring AI in their work. It's designed as an introduction to the core concepts behind AI, demystifying some of the field's vocabulary, helping researchers to understand how they might use AI in their own work, and signposting ways to get started. </p> <ul> <li> <p> What is AI?</p> <p>A look at what AI is, and isn't</p> </li> </ul> <ul> <li> <p> Supervised Learning</p> <p>Supervised Learning</p> </li> </ul> <ul> <li> <p> Unsupervised Learning</p> <p>Unsupervised Learning</p> </li> </ul> <ul> <li> <p> Reinforcement Learning</p> <p>Reinforcement Learning</p> </li> </ul> <ul> <li> <p> Generative AI</p> <p>Generative AI</p> </li> </ul> <ul> <li> <p> Natural Language Processing</p> <p>Natural Language Processing</p> </li> </ul> <ul> <li> <p> Computer Vision</p> <p>Computer Vision</p> </li> </ul> <ul> <li> <p> Training AI Models</p> <p>Training AI Models</p> </li> </ul> <ul> <li> <p> Evaluating AI Models</p> <p>Evaluating AI Models</p> </li> </ul> <ul> <li> <p> Data for AI</p> <p>Data for AI</p> </li> </ul> <ul> <li> <p> Responsible Research and Innovation</p> <p>Responsible Research and Innovation</p> </li> </ul> <ul> <li> <p> Some Practical Advice</p> <p>Some practical advice</p> </li> </ul> <ul> <li> <p> Next Steps</p> <p>Next Steps</p> </li> </ul>"},{"location":"#contact","title":"Contact","text":"<p>If you can't find what you need, or just need more help</p> <p>CONTACT US </p>"},{"location":"data/","title":"Data for AI","text":""},{"location":"data/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>What data is and how it's stored</li> <li>How much data you need and how dataset size impacts your options</li> <li>Data issues</li> <li>Where researchers look for data</li> </ul>"},{"location":"data/#dealing-with-data","title":"Dealing with data","text":"<p>To build an AI model, you'll be working closely with data. Data can make or break your project, and so it's crucial to think carefully about the data you're using and how it'll impact your task. </p> <p>The data you use for your AI work is tightly connected with what you are trying to achieve. If you are building a system that translates between languages, then your data will be text in the languages you're interested in. If you're diagnosing medical conditions, then your data will likely be medical test results or biomarkers. </p> <p>Data can be stored in several formats, whether it's in a spreadsheet, as files on your local machine, or in the cloud.</p> <p>It is transformed into something computer readable by feature extraction, which is the step to convert your data into a numerical format for AI models to use. </p> <p>To use your data, you'll need to split it into several parts. One part will be for training your model, one part for development work, and one for the testing of your model at the end of your work.</p> <p>If you have a dataset, then a common rule of thumb is to use 80% of data for training, 10% for development, and 10% for testing. However, you do need that 10% for testing to be enough data that you can see statistically significant results.</p> <p>Usually you'd randomly sample the test and training set. There may be cases though where you want to do something different. One example is stratified sampling, where you split your data into segments and sample from each segment to be sure you have representation in your test set. Another example is where you may want to be sure that there is no overlap between speakers in test/training data when you have multiple examples (e.g. speech). </p> <p>If you don't have enough data for this split, you can use an N-fold cross validation setup.</p> <p>If you have more data, and from different sources, you might need to carefully think about how to split your data. It's important, for example, that your test set reflects the task you're trying to do. If you use synthetic data in your training, you might keep that out of your test set. </p> <p>Important to keep a split between training and the other sets. Data pre-processing and any parameters are learned on the training set, and then applied to test/validation splits. E.g. if you normalise data then find the parameters on the training set and transfer to test set. This avoids a leakage between test/train. </p>"},{"location":"data/#how-much-data-do-you-need","title":"How much data do you need?","text":"<p>This is a commonly asked question, but there's no hard and fast answer.</p> <p>Task some tasks are inherently easier than others, and require less data. </p> <p>Model the larger your model, the more data you need</p> <p>Diversity you also need diversity in your data as well as quantity. More data that has the same information in won't really improve your model</p> <p>Starting point starting from scratch usually requires more data than if you're finetuning an already existing model.</p> <p>How much data relates to dimension of data too.. need more data for higher dimensional...</p>"},{"location":"data/#data-issues","title":"Data issues","text":"<p>Data drift refers to data where the distribution changes over time.</p> <p>Related is the shift between training and test data distribution. If you collect training data in one way, and test data in another, there may be a difference between the two sets. </p> <p>Skewed data is where there is an imbalance between classes. </p> <p>Data is often the source of many problems with building AI models. husky/wolf example. </p> <p>Depending on what you're doing, your data may contain personal and sensitive information about people. Keeping it safe and secure is crucial. </p>"},{"location":"data/#where-to-get-data-from","title":"Where to get data from","text":"<ul> <li>Collection: can you collect the data you need from volunteers, or by some other way?</li> <li>Open source: there are many open source datasets available, which might work for your task. Many open source sets are ready split into test &amp; training sets for you to use</li> <li>Experimental results: it's common to use AI methods on experimental data from your work or your lab's results. </li> <li>Synthetic: Generating synthetic data is an increasingly common way to create training data. </li> <li>Partnerships: partnering with other labs or organisations to share data can be an effective way to boost the amount of data you're working with</li> </ul>"},{"location":"data/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"evaluating/","title":"Evaluating AI Models","text":""},{"location":"evaluating/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>Using test data to robustly evaluate models</li> <li>Quantative vs qualitative evaluation</li> <li>Evaluation metrics</li> <li>Error analysis tools including confusion matrices &amp; ROC</li> </ul>"},{"location":"evaluating/#data-split","title":"Data split","text":"<p>Split your data into train/test/dev splits If you have a small set, something like k-fold cross validation is the best bet. </p>"},{"location":"evaluating/#qualitative-vs-quantative","title":"Qualitative vs Quantative","text":"<p>There are two main categories of way to evaluate how well your model is working</p> <ol> <li>Devise an automated metric which you can run to find a score</li> <li>Ask people to interact with your model and judge it</li> </ol>"},{"location":"evaluating/#metrics","title":"Metrics","text":"<p>All AI models make mistakes. Metrics depend on what it is you're trying to do.</p> <p>Automated metrics are run over a test dataset. For classification, some common ways to judge performance are:</p> <ul> <li>Accuracy is simply how often the classifier is right</li> <li>Precision tells you for a category, how many things predicted to be in that category actually belong to that category. </li> <li>Recall tells you for a category, how many things of that category are predicted as being in that category. </li> </ul> <p>Precision and recall are used together. An increase in one usually means a decrease in the other. </p> <p>For regression tasks,</p> <ul> <li>RMSE root mean squared error, is a measure of how far on average your predictions are from the ground truth. </li> </ul> <p>You need to use your judgement to interpret a particular metric. An accuracy or 5% may be great for one task, but terrible for another. </p>"},{"location":"evaluating/#error-analysis","title":"Error Analysis","text":"<p>Usually, you will want to look deeper at the kind of errors that a model is making, in order to identify places where you can improve. Some useful ways to view are:</p> <ul> <li>Confusion matrix</li> <li>ROC </li> </ul>"},{"location":"evaluating/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"generative-ai/","title":"Generative AI","text":""},{"location":"generative-ai/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>What generative AI is, and where you can use it</li> <li>What frontier or foundation models are and the pros &amp; cons of using them</li> <li>Some real-world examples of generative AI in research</li> </ul>"},{"location":"generative-ai/#overview","title":"Overview","text":"<p>Since 2017, there has been a lot of work in the area of generative AI. Broadly speaking, generative AI refers to models that generate content, usually in the form of images, text, video or audio.</p> <p></p> <p>In many ways, generative AI is similar to supervised learning. The predictions that the models make are actually predictions about the content itself. You might hear the term self-supervised to describe these models. This is because we don't need a person to label the data as the supervision signal is present within the data itself. </p> <p>One big difference between generative AI and more classic supervised learning is that the kind of content (image, text, audio etc.) that's popular for generative AI models is widely available online. This means that organisations can build larger and larger models with massive training data sets. </p> <p>Generative AI was spurred on recently by the introduction of the transformer model (a kind of neural network) in 2017, and more recent work in building large models. In the field of natural language processing (NLP), transformer models have had a huge impact. Generative AI in NLP uses the task of language modelling - the task of predicting the next word in a sentence. This is a supervised learning task. Given a sequence of words, the model's goal is to predict the next word. It doesn\u2019t require large amounts of effort to label the text data for training because \u201cnext word\u201d is inherently there in the data. A language model is essentially a very powerful autocomplete model, but additional types of training is used to turn a basic language model into a chat model like ChatGPT. </p> <p>What\u2019s interesting about Generative AI models for NLP is that when trained on large amounts of data, they are able to do several tasks that they weren\u2019t explicitly trained to do. For example, with a large amount of multilingual training data, they are able to translate between languages. This is described as zero shot learning.</p> <p>Tasks involving image and audio processing tend to make use of diffusion models rather than transformers. </p>"},{"location":"generative-ai/#frontierfoundation-models","title":"Frontier/Foundation Models","text":"<p>Generative AI models are expensive to train, due to their large size and the large amount of training data. There's a current trend of building larger and larger models. That means that only a handful of organisations can afford to build their own models from scratch. A typical way of working now is that these large \u2018foundation models\u2019 trained once by an organisation with the money and resources to do so, are then released publicly. Others can then use the models directly, or fine-tune them for their own projects with a small amount of data - far smaller than the amount of data that\u2019s needed to build their own large model from scratch.</p> <p>There are some considerations to take into account when using foundation models:</p> <ul> <li>For many public models, there are varying levels of openness. Often the model weights might be available, but we might not know about the training data that was used. </li> <li>If a model is hosted by an organisation behind an API, we cannot be sure what changes they are making, and that can affect reproducibility</li> <li>These models are typically trained on large amounts of data from the internet, which brings with it societal biases that become embedded in the model.</li> <li>There's a large environmental cost to using these models.</li> </ul>"},{"location":"generative-ai/#inspiration","title":"Inspiration","text":"<p>Here are two papers that look at applications of some of these models:</p> <ul> <li>An Interdisciplinary Outlook on Large Language Models for Scientific Research</li> <li>An Overview of Diffusion Models: Applications, Guided Generation, Statistical Rates and Optimization</li> </ul>"},{"location":"generative-ai/#more-resources","title":"More Resources","text":"<p>Accelerate Science has two workshops related to generative AI, each with online material that you can work through at your own pace:</p> <ul> <li>LLMs</li> <li>Diffusion Models</li> </ul>"},{"location":"generative-ai/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"image/","title":"Image Processing / Computer Vision","text":""},{"location":"image/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>What Computer Vision (CV) is</li> <li>Some of the tasks that fall under CV</li> </ul>"},{"location":"image/#what-is-computer-vision","title":"What is Computer Vision?","text":"<p>CV deals with images and video.</p> <p>Across the sciences, there are other sources of image data such as medical images, electron microscopy etc. </p>"},{"location":"image/#cv-tasks","title":"CV Tasks","text":"<p>Many CV tasks exist including:</p> <ul> <li>Classification</li> <li>Segmentation</li> <li>Generation</li> <li>&amp; more</li> </ul>"},{"location":"image/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"next-steps/","title":"Next Steps","text":""},{"location":"next-steps/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>How to get started learning more about AI</li> <li>What help and support is available</li> </ul>"},{"location":"next-steps/#resources","title":"Resources","text":"<p>Now you have an idea how and where AI is used, and hopefully can identify some places in your research where you can see the potential for concrete application of AI.</p> <p>Next places to look:</p> <ul> <li>Our Resource hub contains links to more in depth lessons and tutorials</li> <li>Our workshops on LLMs and Diffusion models</li> <li>Software Engineering help</li> <li>AI Cafe and Clinic sessions</li> </ul>"},{"location":"next-steps/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"nlp/","title":"Natural Language Processing","text":""},{"location":"nlp/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>What falls under the umbrella of Natural Language Processing (NLP)</li> <li>Some of the common NLP tasks</li> </ul>"},{"location":"nlp/#what-is-nlp","title":"What is NLP?","text":"<p>Natural Language Processing (NLP) is the umbrella term for techniques that involve processing text data. NLP is a large domain, and text processing is commonly used across fields. Hence, it can be useful to know some of the ways NLP is used.</p> <p>Recently, the NLP field has moved in the direction of using foundation models and generative AI.</p>"},{"location":"nlp/#nlp-tasks","title":"NLP Tasks","text":"<p>If you want to work with text data in your field, the chances are good that you will want to use some kind of NLP technology. </p> <p>Many common NLP tasks exist, which have a long line of research into them, including:</p> <ul> <li>Lanugage Modelling is the task of predicting the next word, like an autocomplete. It's the basis of recent progress in NLP relating to generative AI. </li> <li>Machine Translation automatically translates text from a source lanugage to a target language. </li> <li>Summarisation is when a model is used to summarise a long piece of text into a shorter one</li> <li>Question Answering answering questions where the answer can be found in a text. E.g. answering questions from a textbook</li> <li>Sentiment Analysis analysing whether a piece of text is positive or negative in its sentiment</li> <li>Named Entity Recognition picking out certain key entities from a phrase. For example, picking out names of cities, countries or people from text. </li> </ul>"},{"location":"nlp/#nlp-data","title":"NLP Data","text":"<p>Data for NLP is text, and often comes from the internet. </p>"},{"location":"nlp/#inspiration","title":"Inspiration","text":""},{"location":"nlp/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"practical/","title":"Some Practical Advice","text":""},{"location":"practical/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>Popular tools for getting started</li> <li>Managing experimentation</li> </ul>"},{"location":"practical/#programming","title":"Programming","text":"<p>Most done in Python - can use notebooks etc. lots of libraries available, industry standard. Pytorch, hugging face &amp; others .</p> <p>R is an alternative</p> <p>Github for managing code &amp; version control</p> <p>Sharing models and code...</p> <p>Accelerate run courses on packaging software &amp; other stuff...</p>"},{"location":"practical/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"reinforcement-learning/","title":"Reinforcement Learning","text":""},{"location":"reinforcement-learning/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>What reinforcement learning is, and where you can use it</li> <li>Some real-world examples of reinforcement learning in research</li> </ul>"},{"location":"reinforcement-learning/#overview","title":"Overview","text":"<p>Reinforcement learning is an area of AI and ML looking at tasks where the computer has to take a series of moves in an uncertain and changing environment, to achieve a particular goal.</p> <p>Reinforcement Learning models learn through trial and error, and are given a reward signal if they achieve their goal. The models aim to optimise their reward. In practice, it's used much less than supervised and unsupervised learning. </p>"},{"location":"reinforcement-learning/#reinforcement-learning-use-cases","title":"Reinforcement Learning Use Cases","text":"<p>RL is used in scenarios like:</p> <ul> <li>Playing games, where the computer can choose to make optimal moves but there is some uncertainty about the moves its opponent may make. </li> <li>Human-computer dialogue, where again the computer can choose an optimal utterance, but there is uncertainty about what the person will say and how that affects the trajectory of the conversation. </li> <li>Controlling robots in real-world environments where there is uncertainty about how the environment changes over time.</li> </ul> <p>In each of these tasks, it\u2019s hard to judge in isolation whether a single turn or move by the computer is optimal. Yet, we do know in the long-term whether the computer achieves its goal.</p>"},{"location":"reinforcement-learning/#inspiration","title":"Inspiration","text":"<ul> <li>One famous example of reinforcement learning is Deepmind's AlphaGo model, that learned to play the game Go</li> </ul>"},{"location":"reinforcement-learning/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"responsible-research-innovation/","title":"Responsible Research and Innovation","text":""},{"location":"responsible-research-innovation/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>Some of the limitations of AI models</li> <li>The wider risks of AI</li> <li>Regulation that might apply</li> </ul>"},{"location":"responsible-research-innovation/#ai-model-limitations","title":"AI model limitations","text":"<p>When using AI, it's important to know about</p> <p>Hallucinations are the name given to a specific </p> <p>Accuracy models aren't 100% accurate</p> <p>Appropriateness some tasks just aren't appropriate for AI</p> <p>Black-box nature of many models</p>"},{"location":"responsible-research-innovation/#risks-and-concerns","title":"Risks and Concerns","text":"<p>Bias</p> <p>Environment</p> <p>Accountability and human oversight</p> <p>Reproducibility</p> <p>Source of data copyright, consent etc.</p> <p>Potential for misuse</p> <p>Explainability and Transparency</p>"},{"location":"responsible-research-innovation/#regulation","title":"Regulation","text":"<p>Regulation for AI is being developed, and is a shifting area, so always do your own research into regulations that might apply.</p> <p>The first AI law to pass is the EU's AI act. This regulation has some banned uses of AI, along with some high-risk applications that come with obligations if they are deployed. Most of the act doesn't apply to research, but could come into force if you move to commercialise your work.</p>"},{"location":"responsible-research-innovation/#good-practice","title":"Good Practice","text":"<p>Model Cards and Data Sheets</p>"},{"location":"responsible-research-innovation/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"supervised-learning/","title":"Supervised Learning","text":""},{"location":"supervised-learning/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>What supervised learning is, and where you can use it</li> <li>The difference between classification and regression</li> <li>Some of the supervised learning algorithms you might encounter</li> <li>Some real-world examples of supervised learning in research</li> </ul>"},{"location":"supervised-learning/#what-is-supervised-learning","title":"What is supervised learning?","text":"<p>Supervised learning is one of the most widely used types of machine learning in the field of AI. Supervised models make predictions about their inputs. They learn how to make those predictions from a dataset of examples that are labelled with the correct prediction (also called the ground truth).</p> <p>Our job in using supervised learning is to define what the input and output of a model should be, to obtain the labelled data, and then to train the model to make accurate predictions. </p> <p></p> <p>One example of supervised learning is that of predicting whether an email is spam or not. In this example, there are two categories, or classes - SPAM and NOT_SPAM.</p> <p>Our machine learning models cannot directly accept email text as input, so first we extract numerical features from each of the emails. Three features might be, for example, the length of the email, the number of spelling mistakes, and the number of dollar signs in the email. </p> <p></p> <p>By training the model directly on a dataset of emails that have been labelled as being spam or not, the model can learn the patterns that identify the two types of email, and then predict for a new email whether it is spam or not. </p>"},{"location":"supervised-learning/#classification-and-regression","title":"Classification and Regression","text":"<p>Supervised learning can either be classification or regression.</p> <p>Classification is where the output is one of a fixed number of categories. This could be a binary classification task where there are exactly two possible outputs, like the example above of spam email detection.  You can think of the model as finding a line to separate the two classes, as here:</p> <p></p> <p>Usually, there's some overlap between our classes, but we can find a good way to separate them. Usually though, classifiers find a way to separate two classes that is more complex than just a straight line. </p> <p>A different task might have multiple categories that an input could belong to. For example, recognising the face of a person in a photo. There are many possible people who could be pictured in the photo, and each person is a possible category.</p> <p></p> <p>In other scenarios, an input might have more than one label. For example, a photo might have two or more different people in it, and we'd like to identify each. This is called multi-label classification, because each photo has more than one label associated with it.</p> <p>Sometimes the number of classes can be very large, in the thousands or millions, as in the case of many language processing tasks. Automatically translating text from one language to another is a supervised task, where the model predictions are words in the target language. </p> <p>Regression is similar to classification, except that the output is a continuous number rather than a discrete class. Examples might be predicting the toxicity of a molecule on a scale. Fitting a line of best fit is a simple kind of regression. </p> <p></p>"},{"location":"supervised-learning/#feature-extraction","title":"Feature Extraction","text":"<p>It's worth noting that machine learning models require numerical inputs, and you'll need to consider in designing your setup. Some tasks naturally have numerical inputs already - whether that's data from sensors, medical tests, pixel values or some other kind of data that's naturally a number. In other tasks, like in text processing, we need to convert our input to a numerical format by extracting features.</p>"},{"location":"supervised-learning/#examples-of-supervised-learning","title":"Examples of Supervised Learning","text":"<p>Examples of supervised learning tasks include:</p> Task Input Prediction Segment tumours in medical images Medical images Areas which are tumours Toxicity prediction Chemical formula Toxicity Medical Diagnosis Biomarkers, test results etc. Diagnosis Automated transcription Audio files Written transcription Machine translation Text in the source language Text in the target language"},{"location":"supervised-learning/#types-of-supervised-learning-model","title":"Types of Supervised Learning Model","text":"<p>Some of the common supervised learning algorithms you might encounter are:</p> <ul> <li>Linear Regression</li> <li>Logistic Regression</li> <li>Decision Trees </li> <li>Support Vector Machines</li> <li>Neural Networks</li> </ul> <p>Much of the recent excitement around AI focuses on neural network approaches. However, depending on your data and task, the other algorithms may be more practical to use.</p>"},{"location":"supervised-learning/#top-tips-for-getting-started","title":"Top Tips for getting started","text":"<ol> <li>A great place to begin is by thinking about the task you want to used supervised learning for. Can you define your task as a supervised learning one? What are the inputs and predictions of your model?</li> <li>Next, think about the data you have. Can you label it easily?</li> <li>Evaluating your model is also important, and at this point it's feasible to think about how you'll evaluate whether your system is working. What metrics could you use?</li> <li>What are the risks and concerns with your proposed work?</li> </ol> <p>Once you've answered these questions, you're ready to move onto training a model.</p>"},{"location":"supervised-learning/#inspiration","title":"Inspiration","text":"<p>Find more examples of research using supervised learning on Accelerate's blog:</p> <ul> <li>Nicola Moloney talks about using supervised learning to predict where proteins are localised within a cell</li> <li>Joyce Nakatumba-Nabende discusses how speech recognition can be deployed to help farmers in Uganda</li> <li>Yizhou Wan tells us how AI can be used to segment brain tumours in images, and to estimate their volume</li> <li>Chris Bannon hopes to predict whether someone's gut biome or metabolic marker levels are that of a healthy person, or whether they have a metabolic or bowel condition</li> </ul>"},{"location":"supervised-learning/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"training/","title":"Training ML Models","text":""},{"location":"training/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>Know what it means to train an AI model</li> <li>How to use data for robust training, development and testing</li> <li>Over and under fitting</li> <li>Tuning hyperparameters</li> <li>Transfer learning and fine tuning</li> <li>Know about the iterative approach to building a model</li> </ul>"},{"location":"training/#training-supervised-models","title":"Training supervised models","text":"<p>Training a supervised learning algorithm involves:</p> <p></p> <ol> <li>decide on the task and collect data; label that data</li> <li>train a model on a 'training' set of your data</li> <li>evaluate the model on a separate test set, to see how well it does</li> <li>investigate the errors to see where you can improve</li> </ol> <p>This tends to be an iterative process, not a linear one, so you may need to loop through these steps several times to get a model that works. </p>"},{"location":"training/#what-is-training","title":"What is training?","text":"<p>Model training is the process of feeding data examples to your model so that it can learn. Usually, models are generic and have a lot of numbers (parameters). Training is the process of learning those parameters. The number of parameters varies wildly between models. A small linear regression model might have in the order of 10 parameters, while a state-of-the-art generative AI model might have 10 billion parameters. </p> <p>A linear regression model trained on one dataset might have the same number of parameters as that trained on another, but the parameter values are different.</p> <p>Training is an interative process where you feed data into the model, it figures out how wrong the model is for those values, and then makes small adjustments to the parameters to be a little better. Over time, with lots of iterations, the parameters get to model the data well. </p>"},{"location":"training/#data","title":"Data","text":"<p>The first thing to do when training a model is to separate your data into testing and training.  Split your data into train, test, dev splits. Really important to ensure no leakage between training and testing. Shuffling your data</p>"},{"location":"training/#over-and-under-fitting","title":"Over and under fitting","text":"<p>Two ways that training can do badly are over and under fitting.</p> <p>Overfitting is where you have a small amount of data and a complex model, so the model learns to model the training set really well. In this case, the model will perform really well on the training set, but poorly on your test set. </p> <p>Underfitting is the opposite, where you might have a lot of data and a simple model, so the model doesn't do well at approximating the data. In this case the model will perform poorly on both your training and test set. </p>"},{"location":"training/#hyperparameters","title":"Hyperparameters","text":"<p>When training, we mentioned the model parameters above, that get modified by the training process. There are other parameters too, called hyperparameters, that you might need to tune. These might be, for example, the number of layers in your neural network, or the learning rate of your training algorithm.</p> <p>We usually keep a separate development set for use with tuning hyperparameters. This lets us keep the test set held out, and avoid overfitting.</p>"},{"location":"training/#transfer-learning-and-fine-tuning","title":"Transfer Learning and Fine Tuning","text":"<p>You do not always need to train a model from scratch. Often, there can be a model out there which you can use as a starting point. Then, you would finetune that model to your data, or use transfer learning.</p> <p>Finetuning is where you keeo the model as it is, and just train the model a bit more on your data</p> <p>Transfer learning is similar to finetuning, but with the understanding that you're training the model for a different task than the one it was originally trained to do. With neural networks, this typically means replacing the last layer with one which is designed for your task.</p> <p>Examples...</p> <p>With these techniques, there are many options for how to do this learning efficiently. </p>"},{"location":"training/#top-tips-for-getting-started","title":"Top Tips for getting started","text":"<ol> <li>Look at what's already been built. Something like Hugging Face has a large repository of models, and yet more models are built and released by different groups around the world.</li> <li>Consider whether you can build a baseline system without ML/AI. This will be simple to do, and give you some insight into your problem. </li> <li>Prototype - start with a small model and a simple baseline; Start with a small dataset, before increasing the amount of data</li> <li>Ensure there's no leakage between your test and training data</li> <li>Make use of open source libraries, models and data</li> </ol>"},{"location":"training/#inspiration","title":"Inspiration","text":"<p>Find more examples of research that's using supervised learning on Accelerate's blog:</p> <ul> <li>link</li> <li>link</li> <li>link</li> </ul>"},{"location":"training/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"unsupervised-learning/","title":"Unsupervised Learning","text":""},{"location":"unsupervised-learning/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>What unsupervised learning is, and where you can use it</li> <li>Unsupervised learning tasks including clustering, outlier detection and dimensionality reduction</li> <li>Some real-world examples of unsupervised learning in research</li> </ul>"},{"location":"unsupervised-learning/#overview","title":"Overview","text":"<p>Supervised learning is the most popular form of AI. However, supervised learning requires labelled data, which can be difficult or expensive to obtain. Most of the data in the world is unlabelled. Unsupervised learning helps us make sense of unstructured and unlabelled data.</p> <p>Three common unsupervised algorithms are clustering, dimensionality reduction and anomaly detection.</p>"},{"location":"unsupervised-learning/#unsupervised-learning-algorithms","title":"Unsupervised Learning Algorithms","text":"<p>Clustering</p> <p>Clustering is the process of taking your data and discovering sub-groups, or clusters, that are sufficiently similar to each other. Unlike classification in supervised learning, where we know the groups ahead of time, clustering uncovers the structure of the groups in a larger population.</p> <p>Suppose you're working with medical data. You know that some groups of people respond differently to treatment than others, but you don't know the factors that drive this. A clustering algorithm might group your participants into different clusters that potentially allow you to better explain what's going on.</p> <p></p> <p>Other places that people have used clustering include uncovering structure in archeological data, clustering sounds and speakers together, identifying sub-groups of study participants etc. </p> <p>K-means and DBSCAN are popular clustering algorithms. You may need to give the number of clusters before running the clustering algorithm, or you might use an automated method to try and find which number of clusters best fits the data. </p> <p>Dimensionality reduction</p> <p>High dimensional data is hard to work with. The first thing we usually notice is that it's hard to visualise well in high dimensions, so that you can explore what the data looks like. A high number of dimensions also imacts the number of parameters your AI model needs to model the data. The more parameters a model has, the larger model and more data you need. This is the curse of dimensionality.</p> <p>Reducing the dimensionality of your data can be one way to work with it effectively. Projecting down to 2- or 3-dimensions means that you can plot it on a graph to view.</p> <p></p> <p>Principal Component Analysis (PCA), t-SNE, and UMAP are popular dimensionality reduction algorithms that you might see used. </p> <p>Anomaly Detection</p> <p>Anomoly detection is identifying anomolous or rare examples in a dataset, that are inconsistent with the rest of the dataset.</p> <p></p> <p>Examples of this might be in identifying fraudulent and unusual bank transactions, or identifying unusual behaviour that might be a cybersecurity threat. </p>"},{"location":"unsupervised-learning/#inspiration","title":"Inspiration","text":"<p>Find more examples of research using unsupervised learning on Accelerate's blog:</p> <ul> <li>Ema Bauzyte discusses using unsupervised learning to cluster sites in archeology, get more insight about which might be related</li> <li>Jesse Allardice uses dimensionality reduction in Physics, to reduce the complexity of high dimensional data for solar panels</li> <li>Dr Romit Samanta groups patients to better identify subgroups of patients and understand how their biology relates to disease progression</li> </ul>"},{"location":"unsupervised-learning/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"},{"location":"what-is-ai/","title":"What is AI?","text":""},{"location":"what-is-ai/#learning-objectives","title":"Learning Objectives","text":"<p>This section will help you understand:</p> <ul> <li>What AI is and where it is used</li> <li>Some different definitions of AI and related terms</li> </ul>"},{"location":"what-is-ai/#overview","title":"Overview","text":"<p>AI has grown in popularity over the past decade, and is cropping up in many places. If you're a researchers who wants to use AI in your work, it's helpful to understand what AI is and to think about how you can use it effectively. </p> <p>This short online course is a set of resources to explain the core concepts behind AI, without the need for maths and programming. The goal is to allow researchers to explore the ideas behind AI and how they might work in research, before diving in to learn more. </p> <p>Artificial Intelligence (AI) doesn\u2019t have a strict definition. Usually it\u2019s thought of as something like imitating human intelligence. AI systems are used to automate decision making in tasks that typically need some level of intelligence to perform. </p> <p>[VIDEO IDEA: vignettes from different people with different perspectives on \u2018what is AI?\u2019; maybe something from the Hopes and Fears Lab]</p> <p>Machine Learning (ML) is a set of algorithms that learn their behaviour from data. This is in contrast to spelling out the rules that a computer must follow. Most of the recent success in AI has been down to Machine Learning. There are 3 broad categories of ML that this course will explore:</p> <ul> <li>Supervised Learning</li> <li>Unsupervised Learning</li> <li>Reinforcement Learning</li> </ul> <p>Under the umbrella of ML, there are many different algorithms. Deep Learning, or Deep Neural Networks, are popular today because they\u2019ve had big success. There are many other algorithms though, some of which may be more suitable for your data.</p>"},{"location":"what-is-ai/#ai-in-the-world","title":"AI in the world","text":"<p>In the AI world, we often talk about tasks. A task is something specific that a model might do such as:</p> <ul> <li>Make a decision about whether an email is spam or not</li> <li>Identify people in images</li> <li>Translate text from one language into another</li> <li>Predict whether a transaction on your credit card is fraudulent</li> <li>Automatically transcribe your speech</li> <li>Play the game of Go with an opponent</li> <li>Predict whether an X-ray shows a cancerous mass</li> <li>Predict the toxicity of a chemical compound</li> </ul> <p>Tasks usually have datasets associated with them, which is lots of examples of the task. For example, a spam email detection dataset would consist of many emails. A speech recognition dataset would consist of audio files of people speaking. </p> <p>A dataset might have labels (or annotations), which are the gold standard, or the correct answer, for each item in the dataset. The emails in your spam email dataset would have labels marking each email as spam or not. The audio files in your speech recognition dataset would have accurate transcriptions of the words spoken. </p> <p>Many popular AI tasks have open source datasets that are available to use. Depending on what people have done in your task before, you might need to go and collect your own dataset. </p> <p>An ML model is built to perform a task, using one or more datasets. The model is usually the artefact that is the result of your experimentation, and it can be used again and again on new data (with some caveats, which we\u2019ll go into further down the line). </p>"},{"location":"what-is-ai/#what-will-this-course-give-me","title":"What will this course give me?","text":"<p>This course will explain some of the concepts and build up an intuition about how AI and ML systems work, without relying on any specific knowledge. This will help you understand how and where AI and ML might be useful in your work, and giving you the basis to dig further. </p> <p>To take this further, and really understand the theory of AI, you\u2019ll need to dig into these topics, which are beyond the scope of this course:</p> <ul> <li>Maths - the theory of machine learning relies on some core maths knowledge, including linear algebra, optimisation, probability and calculus. To understand the theory of AI and ML, and if you want to work on your own models and algorithms, you\u2019ll need to learn this maths.</li> <li>Programming - there are some tools you can use without any particular expertise (e.g. ChatGPT), but if you want to do anything more complicated with AI then you\u2019ll need to know some programming. Python is the language of choice for many ML Scientists, though R is also used in some domains. Accelerate Science works with Cambridge Spark to provide this education.</li> <li>Data Literacy - AI and ML is all about working with datasets - collecting, cleaning, processing, visualising, aggregating &amp; exploring data. This intuition is often built up over time, working with different algorithms, tasks, and datasets.</li> </ul>"},{"location":"what-is-ai/#where-else-can-i-look","title":"Where else can I look?","text":"<p>We recommend this textbook:</p> <p>Hands-on machine\u00a0learning\u00a0with Scikit-Learn,\u00a0Keras,\u00a0and TensorFlow\u00a0: concepts, tools, and techniques to build intelligent systems / Aur\u00e9lien G\u00e9ron.</p> <p>This book has code and exercises that illustrate many of the concepts in this course.</p>"},{"location":"what-is-ai/#contact","title":"Contact","text":"<p>If you can't find what you need</p> <p>CONTACT US </p>"}]}