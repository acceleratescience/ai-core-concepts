# Responsible Research and Innovation


## Learning Objectives
This section will help you understand:

- Some of the limitations of AI models
- The wider risks of AI
- Regulation that might apply

## AI model limitations

When considering AI in your research, it's important to know about some of the limitations of current AI models. These include:

Models don't have 100% **accuracy**, and so aren't appropriate for all scenarios or tasks. This needs to be taken into account in the design of the scenario you imagine AI to be used in. In safety critical tasks, they may always need human oversight. 

**Appropriateness** some tasks just aren't appropriate for AI because they are too noisy or unpredictable. Often, if it sounds too good to be true, then it is! 

The **black-box** nature of many models mean that it can be difficult to understand or interpret why AI models make the predictions that they do. For some domains, this can be challenging. 

**Hallucinations** are the name given to a specific kind of error made by language models outputting factually incorrect information. 

## Risks and Concerns

**Bias**

**Environment**

**Accountability** and human oversight

**Reproducibility**

**Source of data** copyright, consent etc.

**Potential for misuse**

**Explainability and Transparency**

## Regulation

Regulation for AI is being developed, and is a shifting area, so always do your own research into regulations that might apply.

The first AI law to pass is the EU's AI act. This regulation has some banned uses of AI, along with some high-risk applications that come with obligations if they are deployed. Most of the act doesn't apply to research, but could come into force if you move to commercialise your work.




## Contact

If you can't find what you need

[CONTACT US :fontawesome-solid-paper-plane:](mailto:accelerate-mle@cst.cam.ac.uk){ .md-button }





